{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxKxYVt0yBdzF0MOwfXZ0S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tobias-2/FINALL-REPOSITORIES-FROM-COLAB/blob/main/18_3Zadanie_model_klasyfikacji.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvzbmgHYMHUw"
      },
      "outputs": [],
      "source": [
        "!pip install scikeras\n",
        "!pip install tensorflow\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier # Import KerasClassifier from scikeras.wrappers\n",
        "from tensorflow.keras.utils import to_categorical # Import to_categorical instead of np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "iris = sns.load_dataset('iris')\n",
        "iris"
      ],
      "metadata": {
        "id": "nSfFoz20MSHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.2.0 # Downgrade scikit-learn"
      ],
      "metadata": {
        "id": "_mJaLllcMT9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import load_iris\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = sns.load_dataset('iris')\n",
        "\n",
        "# Prepare the data\n",
        "X = iris.iloc[:, 0:4].values\n",
        "y = iris.iloc[:, 4].values\n",
        "\n",
        "# Encode the target variable\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "encoded_Y = encoder.transform(y)\n",
        "dummy_y = to_categorical(encoded_Y)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8, input_dim=4, activation='relu'))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the KerasClassifier\n",
        "estimator = KerasClassifier(build_fn=create_model, epochs=200, batch_size=5, verbose=0)\n",
        "\n",
        "# Evaluate the model using k-fold cross-validation\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold) # This line caused the error\n",
        "\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "\n",
        "# Train the final model on the entire dataset\n",
        "model = create_model()\n",
        "model.fit(X, dummy_y, epochs=200, batch_size=5, verbose=0)\n",
        "\n",
        "\n",
        "# Example prediction (replace with your actual data)\n",
        "new_data = np.array([[5.1, 3.5, 1.4, 0.2]]) # Example data point\n",
        "prediction = model.predict(new_data)\n",
        "predicted_class = np.argmax(prediction)\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "\n",
        "#To see the probabilities for each class\n",
        "print(f\"Probabilities: {prediction}\")\n",
        "\n",
        "# Decode the predicted class back to the original label\n",
        "predicted_species = encoder.inverse_transform([predicted_class])\n",
        "print(f\"Predicted species: {predicted_species[0]}\")"
      ],
      "metadata": {
        "id": "PqC560O1MWHI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}